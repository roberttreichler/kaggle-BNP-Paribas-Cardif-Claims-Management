{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#script by Rob Treichler...basic python script score -> 0.45894\n",
    "\n",
    "#create working directory\n",
    "import os#Miscellaneous operating system interfaces\n",
    "os.chdir(r'C:\\\\Users\\\\rtreichl\\\\Documents\\\\competitions\\\\BNP Paribas Cardif Claims Management')  #working directory\n",
    "\n",
    "#%matplotlib inline allows graphics to show below each cell (or graphics in line)\n",
    "# for some reason, %matplotlib inline won't work if comments are made in the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd #munging and wrangling\n",
    "import numpy as np  #for arrays, etc.\n",
    "import matplotlib.pyplot as plt #graphs/plots\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Model Selection -> Metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#xgboost\n",
    "import xgboost as xgb #xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use dataframes for EDA\n",
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Encoding categorical features\n",
    "\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(np.unique(list(train[f].values) + list(test[f].values)))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flag missing values....these may have predictive value\n",
    "clist=list(train.columns[2:133])\n",
    "for i in clist:\n",
    "    train[i + \"_miss\"]=np.where(train[i].notnull(),0,1)\n",
    "    test[i + \"_miss\"]=np.where(test[i].notnull(),0,1)\n",
    "\n",
    "#drop variables that don't have missing values\n",
    "drop_miss_list=[\n",
    "'v3_miss',\n",
    "'v22_miss',\n",
    "'v24_miss',\n",
    "'v30_miss',\n",
    "'v31_miss',\n",
    "'v38_miss',\n",
    "'v47_miss',\n",
    "'v52_miss',\n",
    "'v56_miss',\n",
    "'v62_miss',\n",
    "'v66_miss',\n",
    "'v71_miss',\n",
    "'v72_miss',\n",
    "'v74_miss',\n",
    "'v75_miss',\n",
    "'v79_miss',\n",
    "'v91_miss',\n",
    "'v107_miss',\n",
    "'v110_miss',\n",
    "'v112_miss',\n",
    "'v113_miss',\n",
    "'v125_miss',\n",
    "'v129_miss',]\n",
    "\n",
    "for dml in drop_miss_list:\n",
    "    try:\n",
    "        train=train.drop(dml,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "for dml in drop_miss_list:\n",
    "    try:\n",
    "        test=test.drop(dml,axis=1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#impute missing values\n",
    "#imputation strategy is median\n",
    "\n",
    "imp = preprocessing.Imputer(strategy='median',axis=1)\n",
    "\n",
    "\n",
    "for i in train.columns[2:133]:\n",
    "    temp=pd.DataFrame((imp.fit(train[i]).transform(train[i])).reshape(-1,1))\n",
    "    train[i]=temp\n",
    "for i in test.columns[1:132]:\n",
    "    temp=pd.DataFrame((imp.fit(test[i]).transform(test[i])).reshape(-1,1))\n",
    "    test[i]=temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform variables to roughly the same scale\n",
    "\n",
    "#use log base 10 and natural log to tighten things up a bit (outlier management)\n",
    "\n",
    "#transform log 10\n",
    "log10_list=['v22','v56','v125','v113']\n",
    "for l10 in log10_list:\n",
    "    train[l10]=np.where(train[l10]<= 0,np.log10(np.absolute(train[l10])+1)*-1,np.log10(train[l10]+1))\n",
    "    test[l10]=np.where(test[l10]<= 0,np.log10(np.absolute(test[l10])+1)*-1,np.log10(test[l10]+1))\n",
    "\n",
    "#transform ln\n",
    "ln_list=['v1',\n",
    "'v2',\n",
    "'v4',\n",
    "'v5',\n",
    "'v6',\n",
    "'v7',\n",
    "'v8',\n",
    "'v9',\n",
    "'v10',\n",
    "'v11',\n",
    "'v12',\n",
    "'v13',\n",
    "'v14',\n",
    "'v15',\n",
    "'v16',\n",
    "'v17',\n",
    "'v18',\n",
    "'v19',\n",
    "'v20',\n",
    "'v21',\n",
    "'v23',\n",
    "'v25',\n",
    "'v26',\n",
    "'v27',\n",
    "'v28',\n",
    "'v29',\n",
    "'v30',\n",
    "'v32',\n",
    "'v33',\n",
    "'v34',\n",
    "'v35',\n",
    "'v36',\n",
    "'v37',\n",
    "'v38',\n",
    "'v39',\n",
    "'v40',\n",
    "'v41',\n",
    "'v42',\n",
    "'v43',\n",
    "'v44',\n",
    "'v45',\n",
    "'v46',\n",
    "'v47',\n",
    "'v48',\n",
    "'v49',\n",
    "'v50',\n",
    "'v51',\n",
    "'v52',\n",
    "'v53',\n",
    "'v54',\n",
    "'v55',\n",
    "'v57',\n",
    "'v58',\n",
    "'v59',\n",
    "'v60',\n",
    "'v61',\n",
    "'v62',\n",
    "'v63',\n",
    "'v64',\n",
    "'v65',\n",
    "'v67',\n",
    "'v68',\n",
    "'v69',\n",
    "'v70',\n",
    "'v71',\n",
    "'v72',\n",
    "'v73',\n",
    "'v76',\n",
    "'v77',\n",
    "'v78',\n",
    "'v79',\n",
    "'v80',\n",
    "'v81',\n",
    "'v82',\n",
    "'v83',\n",
    "'v84',\n",
    "'v85',\n",
    "'v86',\n",
    "'v87',\n",
    "'v88',\n",
    "'v89',\n",
    "'v90',\n",
    "'v91',\n",
    "'v92',\n",
    "'v93',\n",
    "'v94',\n",
    "'v95',\n",
    "'v96',\n",
    "'v97',\n",
    "'v98',\n",
    "'v99',\n",
    "'v100',\n",
    "'v101',\n",
    "'v102',\n",
    "'v103',\n",
    "'v104',\n",
    "'v105',\n",
    "'v106',\n",
    "'v107',\n",
    "'v108',\n",
    "'v109',\n",
    "'v111',\n",
    "'v112',\n",
    "'v114',\n",
    "'v115',\n",
    "'v116',\n",
    "'v117',\n",
    "'v118',\n",
    "'v119',\n",
    "'v120',\n",
    "'v121',\n",
    "'v122',\n",
    "'v123',\n",
    "'v124',\n",
    "'v126',\n",
    "'v127',\n",
    "'v128',\n",
    "'v129',\n",
    "'v130',\n",
    "'v131',]\n",
    "\n",
    "for ln in ln_list:\n",
    "    train[ln]=np.where(train[ln]<= 0,np.log(np.absolute(train[ln])+1)*-1,np.log(train[ln]+1))\n",
    "    test[ln]=np.where(test[ln]<= 0,np.log(np.absolute(test[ln])+1)*-1,np.log(test[ln]+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create train and test sets\n",
    "\n",
    "x_train=train.ix[:,2:241]\n",
    "\n",
    "y_train=train.ix[:,1:2]\n",
    "\n",
    "x_test=test.ix[:,1:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training and test sets for cross validation\n",
    "x_traincv, x_testcv, y_traincv, y_testcv = cross_validation.train_test_split(x_train,y_train, test_size=0.34, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#final model with submission file\n",
    "#def xg_sub(label,x_train,y_train,x_test,parameters):\n",
    "    #xgb parameters\n",
    "    \n",
    "params = {'objective':'binary:logistic','eval_metric' : 'logloss', 'eta': 0.01,\n",
    "         'subsample':1.0, 'max_depth':9, 'colsample_bytree':0.6,\n",
    "          'nthread':-1}\n",
    "\n",
    "\n",
    "    #train input matrix\n",
    "xgb_train_data = xgb.DMatrix(x_train, y_train)\n",
    "xgb_test_data  = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_estimator = xgb.train(params, xgb_train_data, num_boost_round= 2000)\n",
    "\n",
    "\n",
    "train_pred=pd.DataFrame(xgb_estimator.predict(xgb_train_data))\n",
    "test_pred =pd.DataFrame(xgb_estimator.predict(xgb_test_data))\n",
    "\n",
    "submission_xg = pd.DataFrame(columns=['ID','PredictedProb'])\n",
    "submission_xg['ID']=test['ID']\n",
    "submission_xg['PredictedProb']=test_pred.ix[:,0]\n",
    "submission_xg.to_csv('bnp_2000_1_9_06.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
